{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the file\n",
    "train = pd.read_csv(\"TrainingData.csv\", index_col =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400277, 25)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the loaded dataset has 25 variables and 400277 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400277 entries, 134338 to 415831\n",
      "Data columns (total 25 columns):\n",
      "Function                  400277 non-null object\n",
      "Use                       400277 non-null object\n",
      "Sharing                   400277 non-null object\n",
      "Reporting                 400277 non-null object\n",
      "Student_Type              400277 non-null object\n",
      "Position_Type             400277 non-null object\n",
      "Object_Type               400277 non-null object\n",
      "Pre_K                     400277 non-null object\n",
      "Operating_Status          400277 non-null object\n",
      "Object_Description        375493 non-null object\n",
      "Text_2                    88217 non-null object\n",
      "SubFund_Description       306855 non-null object\n",
      "Job_Title_Description     292743 non-null object\n",
      "Text_3                    109152 non-null object\n",
      "Text_4                    53746 non-null object\n",
      "Sub_Object_Description    91603 non-null object\n",
      "Location_Description      162054 non-null object\n",
      "FTE                       126071 non-null float64\n",
      "Function_Description      342195 non-null object\n",
      "Facility_or_Department    53886 non-null object\n",
      "Position_Extra            264764 non-null object\n",
      "Total                     395722 non-null float64\n",
      "Program_Description       304660 non-null object\n",
      "Fund_Description          202877 non-null object\n",
      "Text_1                    292285 non-null object\n",
      "dtypes: float64(2), object(23)\n",
      "memory usage: 79.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above result, we can see that only 2 columns namely FTE (Full Time Employement) and Total (Total expenses) are numerical. Some of the column names correspond to features - descriptions of the budget items - such as the Job_Title_Description column. The values in this column tell us if a budget item is for a teacher, custodian, or other employee. Some columns correspond to the budget item labels you will be trying to predict with your model. For example, the Object_Type column describes whether the budget item is related classroom supplies, salary, travel expenses, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134338</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>50471.810</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206341</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>CONTRACTOR SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RGN  GOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDESIGNATED</td>\n",
       "      <td>3477.860</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326408</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>62237.130</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364634</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>EMPLOYEE BENEFITS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNALLOC BUDGETS/SCHOOLS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>22.300</td>\n",
       "      <td>GENERAL MIDDLE/JUNIOR HIGH SCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47683</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>TEACHER COVERAGE FOR TEACHER</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>54.166</td>\n",
       "      <td>GENERAL HIGH SCHOOL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Function          Use          Sharing Reporting  \\\n",
       "134338     Teacher Compensation  Instruction  School Reported    School   \n",
       "206341                 NO_LABEL     NO_LABEL         NO_LABEL  NO_LABEL   \n",
       "326408     Teacher Compensation  Instruction  School Reported    School   \n",
       "364634  Substitute Compensation  Instruction  School Reported    School   \n",
       "47683   Substitute Compensation  Instruction  School Reported    School   \n",
       "\n",
       "       Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "134338     NO_LABEL       Teacher                  NO_LABEL  NO_LABEL   \n",
       "206341     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "326408  Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "364634  Unspecified    Substitute                  Benefits  NO_LABEL   \n",
       "47683   Unspecified       Teacher   Substitute Compensation  NO_LABEL   \n",
       "\n",
       "         Operating_Status            Object_Description  \\\n",
       "134338  PreK-12 Operating                           NaN   \n",
       "206341      Non-Operating           CONTRACTOR SERVICES   \n",
       "326408  PreK-12 Operating  Personal Services - Teachers   \n",
       "364634  PreK-12 Operating             EMPLOYEE BENEFITS   \n",
       "47683   PreK-12 Operating  TEACHER COVERAGE FOR TEACHER   \n",
       "\n",
       "                    ...               Sub_Object_Description  \\\n",
       "134338              ...                                  NaN   \n",
       "206341              ...                                  NaN   \n",
       "326408              ...                                  NaN   \n",
       "364634              ...                                  NaN   \n",
       "47683               ...                                  NaN   \n",
       "\n",
       "       Location_Description  FTE     Function_Description  \\\n",
       "134338                  NaN  1.0                      NaN   \n",
       "206341                  NaN  NaN                 RGN  GOB   \n",
       "326408                  NaN  1.0                      NaN   \n",
       "364634                  NaN  NaN  UNALLOC BUDGETS/SCHOOLS   \n",
       "47683                   NaN  NaN              NON-PROJECT   \n",
       "\n",
       "       Facility_or_Department              Position_Extra      Total  \\\n",
       "134338                    NaN               KINDERGARTEN   50471.810   \n",
       "206341                    NaN                UNDESIGNATED   3477.860   \n",
       "326408                    NaN                     TEACHER  62237.130   \n",
       "364634                    NaN  PROFESSIONAL-INSTRUCTIONAL     22.300   \n",
       "47683                     NaN  PROFESSIONAL-INSTRUCTIONAL     54.166   \n",
       "\n",
       "                   Program_Description        Fund_Description  \\\n",
       "134338                    KINDERGARTEN            General Fund   \n",
       "206341   BUILDING IMPROVEMENT SERVICES                     NaN   \n",
       "326408           Instruction - Regular  General Purpose School   \n",
       "364634  GENERAL MIDDLE/JUNIOR HIGH SCH                     NaN   \n",
       "47683    GENERAL HIGH SCHOOL EDUCATION                     NaN   \n",
       "\n",
       "                               Text_1  \n",
       "134338                            NaN  \n",
       "206341  BUILDING IMPROVEMENT SERVICES  \n",
       "326408                            NaN  \n",
       "364634            REGULAR INSTRUCTION  \n",
       "47683             REGULAR INSTRUCTION  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 FTE         Total\n",
      "count  126071.000000  3.957220e+05\n",
      "mean        0.426794  1.310586e+04\n",
      "std         0.573576  3.682254e+05\n",
      "min        -0.087551 -8.746631e+07\n",
      "25%         0.000792  7.379770e+01\n",
      "50%         0.130927  4.612300e+02\n",
      "75%         1.000000  3.652662e+03\n",
      "max        46.800000  1.297000e+08\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEoCAYAAABsGkdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/H+MaA5R2+LAaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa6ef8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the summary statistics\n",
    "print(train.describe())\n",
    "\n",
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a histogram to visualize the FTE column\n",
    "plt.hist(train['FTE'].dropna())\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high variance in 'Total' expenses makes sense (some purchases are cheap some are expensive). Also, it looks like the FTE column is unimodal. That is, maximum number of employees work as part-time employees ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the datatypes of various columns\n",
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence out of 25 variables , 23 are of object type and only 2 variables are of numerical type. Our ultimate goal is to predict the probability that a certain label is attached to a budget line item. There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Encode the labels as categorical variables\n",
    "\n",
    "We need to convert the 9 columns of labels to categorical variables as categorical datatypes are much more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Object_Type         category\n",
      "Operating_Status    category\n",
      "Position_Type       category\n",
      "Pre_K               category\n",
      "Reporting           category\n",
      "Sharing             category\n",
      "Student_Type        category\n",
      "Use                 category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a list containing all the 9 columns of labels\n",
    "LABELS = ['Function', 'Object_Type', 'Operating_Status', 'Position_Type', 'Pre_K','Reporting',\n",
    "          'Sharing','Student_Type','Use']\n",
    "\n",
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "train[LABELS] = train[LABELS].apply(categorize_label, axis=0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(train[LABELS].dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are over 100 unique labels. We need to explore this fact by counting and plotting the number of unique values for each category of label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAFcCAYAAADLSwX8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIyKGRBJ+RMSQSMKPiBgS/z8kyoBUr6K/6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfe598d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = train[LABELS].apply(pd.Series.nunique)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot(kind='bar')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the variable Function has highest number of unique values as compared to other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating a simple model\n",
    "\n",
    "Here i'm training the model only using numerical variables. The first step is to split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least min_count examples of each label appear in each split: multilabel_train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Data columns (total 2 columns):\n",
      "FTE      320222 non-null float64\n",
      "Total    320222 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 413949\n",
      "Data columns (total 2 columns):\n",
      "FTE      80055 non-null float64\n",
      "Total    80055 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Use_Untracked Budget Set-Aside\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 413949\n",
      "Columns: 104 entries, Function_Aides Compensation to Use_Untracked Budget Set-Aside\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Defining the function \"multilabel_train_test_split\"\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).all():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])\n",
    "\n",
    "# Create a list of numeric variables\n",
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "\n",
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = train[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(train[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i will import the logistic regression and one versus rest classifiers in order to fit a multi-class logistic regression model to the NUMERIC_COLUMNS of your feature data. Then i will test and print the accuracy with the .score() method to see the results of training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Create the DataFrame: numeric_data_only\n",
    "numeric_data_only = train[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(train[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! The good news is that the workflow didn't cause any errors. The bad news is that the model scored the lowest possible accuracy: 0.0! This is because we threw away ALL of the text data in the budget. In further sections below,we will be using th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "## Use your model to predict values on holdout data or test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda and Graphlab Create\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda and Graphlab Create\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\base.py:284: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "holdout = pd.read_csv('TestData.csv', index_col=0)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Writing out your results to a csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(train[LABELS]).columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To submit and get the leaderboard score, use:\n",
    "# Submit the predictions for scoring: score\n",
    "# score = score_submission(pred_path='predictions.csv')\n",
    "\n",
    "# Print score\n",
    "# print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us improve the score in leaderboard using NLP insted of supervised model seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLP to make predictions\n",
    "\n",
    "Here we use NLP to improve our leaderboard scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing text numerically\n",
    "### Creating a bag-of-words in scikit-learn\n",
    "\n",
    "The Position_Extra column describes any additional information not captured by the Position_Type label. Hence we can turn the raw text in this column into a bag-of-words representation by creating tokes that contain only alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 385 tokens in Position_Extra if we split on non-alpha numeric\n",
      "[u'1st', u'2nd', u'3rd', u'4th', u'56', u'5th', u'9th', u'a', u'ab', u'accountability', u'adaptive', u'addit', u'additional', u'adm', u'admin']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "train.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(train.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that treating only alpha-numeric characters as tokens gives a smaller number of more meaningful tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining text columns for tokenization\n",
    "\n",
    "CountVectorizer expects each row to just be a single string, so in order to use all of the text columns, we'll need a method to turn a list of strings into a single string. We define a function combine_text_columns(), which will convert all training text data in the train dataframe to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4757 tokens in the dataset\n",
      "There are 3284 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(train)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence tokenizing on alpha-numeric tokens reduced the number of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the model\n",
    "\n",
    "Because the budget data consists of both text and numeric data, we can use pipelines to improve the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FunctionTransformer on the main dataset\n",
    "\n",
    "We first use FunctionTransformer on the primary budget data, before instantiating a multiple-datatype pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(train[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in train.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(train[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a model to the pipeline\n",
    "\n",
    "The structure of the pipeline is as follows:-\n",
    " * The preprocessing step uses FeatureUnion to join the results of nested pipelines that each rely on     FunctionTransformer to select multiple datatypes\n",
    " * The model step stores the model object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nAccuracy on budget dataset: ', 0.34736118918243708)\n"
     ]
    }
   ],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Import the Imputer object\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is      using Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a different model\n",
    "\n",
    "Now that we've built the entire pipeline, we can easily start trying out different models by just modifying the 'clf' step. We can swap out the logistic-regression model and replace it with a random forest classifier, which uses the statistics of an ensemble of decision trees to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nAccuracy on budget dataset: ', 0.90560239835113354)\n"
     ]
    }
   ],
   "source": [
    "# Import random forest classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the accuracy increased to 0.905 after using random forest classifier. We can further adjust the model or parameters to improve accuracy as shown below :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nAccuracy on budget dataset: ', 0.91378427331209788)\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add model step to pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators=15))\n",
    "    ])\n",
    "\n",
    "# Fit with training split\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we used skillful NLP, efficient computation, and simple but powerful stats tricks to master the budget data and develop a higher accuracy model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
